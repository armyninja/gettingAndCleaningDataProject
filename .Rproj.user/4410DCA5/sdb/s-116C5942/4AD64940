{
    "contents" : "## Kevin Reynolds Getting and Cleaning Data Programming Assignment\n\n## ----------\n# run_analysis.R does the following. \n# 1. Merges the training and the test sets to create one data set.\n# 2. Extracts only the measurements on the mean and standard deviation for each measurement. \n# 3. Uses descriptive activity names to name the activities in the data set\n# 4. Appropriately labels the data set with descriptive variable names. \n# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.\n## ----------\n\n#Kevin Reynolds Getting and Cleaning Data - run_analysis.R\n\n# run_analysis.R does the following. \n# 1. Merges the training and the test sets to create one data set.\n# 2. Extracts only the measurements on the mean and standard deviation for each measurement. \n# 3. Uses descriptive activity names to name the activities in the data set\n# 4. Appropriately labels the data set with descriptive variable names. \n# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each \nvariable for each activity and each subject.\n\n#In order for this script to run a user needs to instal the reshape2 package by: install.packages\n('reshape2')\n#user then needs to load the reshape2 library by typeing in library(reshape2)\n#reshape2 is needed for the melt function\n\n#-----\n# Start run_analysis.R\n#------\n\n\n#create the filename\nfile_name <- \"getdata_dataset.zip\" \n\n#check for getdata_dataset.zip and if it is not there, download it\nif (!file.exists(file_name)){\n  file_URL <- \"http://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip\"\n  download.file(file_URL, file_name, method=\"auto\")\n}\n\n#check for getdata_dataset.zip unzipped folder structure and if not there unzip it\nif (!file.exists(\"UCI HAR Dataset\")) { \n  unzip(file_name) \n}\n\n# Load activity_Labels, features\nactivity_Labels <- read.table(\"UCI HAR Dataset/activity_labels.txt\")\nactivity_Labels[,2] <- as.character(activity_Labels[,2])\nfeatures <- read.table(\"UCI HAR Dataset/features.txt\")\nfeatures[,2] <- as.character(features[,2])\n\n# get mean and std into filtered results\nfeatures_filtered <- grep(\".*mean.*|.*std.*\", features[,2])\nfeatures_filtered.names <- features[features_filtered,2]\nfeatures_filtered.names = gsub('-mean', 'Mean', features_filtered.names)\nfeatures_filtered.names = gsub('-std', 'Std', features_filtered.names)\nfeatures_filtered.names <- gsub('[-()]', '', features_filtered.names)\n\n# Load data\nx_train <- read.table(\"UCI HAR Dataset/train/X_train.txt\")[features_filtered]\ny_train <- read.table(\"UCI HAR Dataset/train/Y_train.txt\")\nsubject_train <- read.table(\"UCI HAR Dataset/train/subject_train.txt\")\ntrain <- cbind(subject_train, y_train, x_train)\n\nx_test <- read.table(\"UCI HAR Dataset/test/X_test.txt\")[features_filtered]\ny_test <- read.table(\"UCI HAR Dataset/test/Y_test.txt\")\nsubject_test <- read.table(\"UCI HAR Dataset/test/subject_test.txt\")\ntest <- cbind(subject_test, y_test, x_test)\n\n# merge\nfinal_Data <- rbind(train, test)\ncolnames(final_Data) <- c(\"subject\", \"activity\", features_filtered.names)\n\n# factor\nfinal_Data$activity <- factor(final_Data$activity, levels = activity_Labels[,1], labels = \n                                activity_Labels[,2])\nfinal_Data$subject <- as.factor(final_Data$subject)\n\nfinal_Data.melted <- melt(final_Data, id = c(\"subject\", \"activity\"))\nfinal_Data.mean <- dcast(final_Data.melted, subject + activity ~ variable, mean)\n\n# create tidy.txt\nwrite.table(final_Data.mean, \"tidy.txt\", row.names = FALSE, quote = FALSE)",
    "created" : 1445793568605.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4146162267",
    "id" : "4AD64940",
    "lastKnownWriteTime" : 1445799231,
    "path" : "~/R/course3/runanalysis.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}